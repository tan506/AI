In [2]:
#import mutual information library from microsoft nlp recipe
from Interpreter import calculate_regularization, Interpreter

import oks
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from nltk.corpus import brown
#if error exits, maybe you should excute following
# python
# >> import nltk
# >> nltk.download('brown')
from model import MyModel
"Get word-id lookup table"
"Get charater-id lookup table"
In [3]:
full_sent = []
for w in brown.words():
    full_sent.append(w)
full_sent = ' '.join(full_sent)
character_vocab = set(full_sent)
char_len = len(character_vocab)

word_vocab = []
for w in brown.words():
    word_vocab.append(w)
word_vocab = set(word_vocab)
word_len = len(word_vocab)

word_to_idx = {}
idx_to_word = {}
for idx, word in enumerate(word_vocab):
    #print('%d, %s' % (idx,word))
    word_to_idx[word] = idx
    idx_to_word[idx] = word

    
char_to_idx = {}
idx_to_char = {}
for idx, char in enumerate(character_vocab):
    char_to_idx[char] = idx
    idx_to_char[idx] = char
In [4]:
def n_gram(gram_len,sent):
    '''
    input: number of gram, a sentence(str)
    return: n-grams
    '''
    n_gram_pair = []
    sent_len = len(sent)
    for idx, w in enumerate(sent):
        if  idx+gram_len > sent_len:
            break
        gram = sent[idx:idx+gram_len]
        n_gram_pair.append(gram)
    return n_gram_pair


def get_input_output(n_gram_pair):
    '''
    input: n-grams
    return: input n-1 gram and output 1-gram
    '''
    input_list = []
    output_list = []
    for pair in n_gram_pair:
        input_str = pair[:-1]
        output_str = pair[-1]
        input_list.append(' '.join(input_str))
        output_list.append(output_str)
    return (input_list, output_list)

def convert_into_tensor(word):
    '''
    input: a word(str)
    return: character level word ids(tensor)
    '''
    look = []
    for c in word:
        look.append(char_to_idx[c])
    np_look = np.array(look)  
    return torch.from_numpy(np_look)

def convert_into_numpy(word): 
    '''
    input: a word(str)
    return: character level word ids(numpy)
    '''
    look = []
    for c in word:
        look.append(char_to_idx[c])
    np_look = np.array(look)  
    return np_look#torch.from_numpy(np_look)
"Generate n-1 gram(input) and 1-gram(output)"
In [5]:
n_gram_pair = []
for sent in brown.sents():
    n_gram_pair += n_gram(2,sent)
input_, output_ = get_input_output(n_gram_pair)
"A sample function to get representation from morphs"
In [6]:
def Phi_simple(x):
    '''
    input: morphs vector
    return: summrised a single representation vector
    '''
    summarized_lstm,_ = torch.max(x, 0)
    return summarized_lstm
In [7]:
net = MyModel()
device = 'cpu'
net = net.to(device)
In [9]:
import math
MI = 0

for target_word in input_[9:10]:
    # Do not update CNN network while update perturbation's noise
    for param in net.parameters():
        param.requires_grad = False
    #net.eval()

    # morph_representation: all vectors for representation
    # morphs: morphs(str)
    morph_representation, morphs = net(target_word)

    # calculate the regularization term
    # the same as nlp recipe
    regularization_simple = calculate_regularization(morph_representation, Phi_simple, device=device)
    interpreter_simple = Interpreter(
        x=morph_representation,
        Phi=Phi_simple,
        regularization=regularization_simple,
        scale=10 * 0.1,
        words=morphs,
    )
    #a = interpreter_simple.to(device)
    interpreter_simple.optimize(iteration=1000, lr=0.01, show_progress=True)

    # sigma_numbers: the estimated value of noise variance
    sigma_numbers = interpreter_simple.get_sigma()
    
    # tmp: a single mutual information approximated by moise variance(perturbation theory)
    tmp = len(sigma_numbers)*np.log(2*np.pi*math.e)/2.0  + len(sigma_numbers)*np.sum(np.log(sigma_numbers+0.02))# MI = p(sigma)
    MI += tmp
    
    for param in net.parameters():
        param.requires_grad = True
    net.train()
100%|██████████| 1000/1000 [00:00<00:00, 2334.92it/s]
"Other script( less important)"
In [ ]:

"A singel loop for mutual information estimation"
In [9]:
morph_representation, morphs = net(target_word)
In [ ]:

In [10]:
#morph_representation.size()
#morphs
In [11]:
a = Phi_simple(morph_representation)
print(a.size())
print(morph_representation.size())
torch.Size([100])
torch.Size([1, 100])
In [12]:
# calculate the regularization term
device = 'cpu'
regularization_simple = calculate_regularization(morph_representation, Phi_simple, device=device)

interpreter_simple = Interpreter(
    x=morph_representation,
    Phi=Phi_simple,
    regularization=regularization_simple,
    scale=10 * 0.1,
    words=morphs,
)
interpreter_simple.to(device)
Out[12]:
Interpreter()
In [15]:
#interpreter_simple.optimize(iteration=2000, lr=0.01, show_progress=True)
In [16]:
# Show the sigma we get
sigma_numbers = interpreter_simple.get_sigma()
sigma_numbers
Out[16]:
array([nan], dtype=float32)
In [17]:
# Visualize the information loss of our sigma
interpreter_simple.visualize()

In [4]:

In [2]:

In [ ]:

In [ ]:

In [ ]:

In [35]:
embeds = nn.Embedding(char_len, 30)
w_embeds = nn.Embedding(word_len,100)

conv1 = nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1)
conv2 = nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1)
conv3 = nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1)
conv4 = nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1)
conv_seg = nn.Conv2d(1,1,kernel_size=2,stride=1)
sig = nn.Sigmoid()
linear = nn.Linear(29,1)
lstm = nn.LSTM(30, 100)
In [106]:
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self,inputs, output, char_vocab, word_vocab,max_word_len=40,padding_char='#'):
        root = './'
        self.inputs = inputs
        self.output = output
        
        
    def __getitem__(self,index):
        return self.inputs[index], torch.tensor(word_to_idx[self.output[index]])
    def __len__(self):
        return len(self.inputs)
    
class MyModel(nn.Module):
    def __init__(self):
        super(MyModel,self).__init__()
        self.char_embeds = nn.Embedding(char_len, 30)
        self.word_embeds = nn.Embedding(word_len,100)
        
        self.features = nn.Sequential(
            nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1),
            nn.ReLU(),
            nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1),
            nn.ReLU(),
            nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1),
            nn.ReLU(),
            nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1),
            nn.ReLU(),
            nn.Conv2d(1,1,kernel_size=2,stride=1),
        )
        self.linear = nn.Linear(29,1)
        self.sig = nn.Sigmoid()
        self.lstm = nn.LSTM(30, 100)
    def forward(self,x):
        network_outputs = []
        for w in x:
            original = convert_into_tensor(w)
            char_embedding = self.char_embeds(original)
            lstm_out = []
            if char_embedding.size()[0] == 1:
                _, out2 = self.lstm(char_embedding.unsqueeze(1))
                lstm_out.append(out2[0].view(1,-1))    
                lstm_out = torch.cat(lstm_out,dim=0)
                summarized_lstm,_ = torch.max(lstm_out, 0)
                network_outputs.append(summarized_lstm.unsqueeze(0))
                continue
    
            a = char_embedding.unsqueeze(0)
            a = a.unsqueeze(0)
            seg = self.features(a)
            seg = self.linear(seg)
            seg = self.sig(seg)
        
            idx = torch.where(seg >= 0.505)
            boundries = idx[2] + 1
            outputs = []
            outputs.append(torch.tensor(0).unsqueeze(0))

            outputs.append(boundries)
            outputs.append(torch.tensor(original.size()[0]).unsqueeze(0))
            result = torch.cat(outputs, dim=0)
            morph = []
            for cnt, idx in enumerate(result):
                if(cnt == 0):
                    continue
                morph.append(char_embedding[result[cnt-1]:result[cnt]].unsqueeze(1))

    
            for m in morph:
                _, out2 = self.lstm(m)
                lstm_out.append(out2[0].view(1,-1))
        
            lstm_out = torch.cat(lstm_out,dim=0)
            return lstm_out
            #summarized_lstm,_ = torch.max(lstm_out, 0)
            
            #network_outputs.append(summarized_lstm.unsqueeze(0))
                
        #representation = torch.cat(network_outputs,dim=0)
        #out_words_embedding = self.word_embeds(y) 
        #return representation#out_words_embedding
    
def get_morph_representation(word,chars):
    #original = convert_into_tensor(word)
    #print(original.size())
    #char_embedding = embeds(original)
    lstm_out = []
    #if char_embedding.size()[0] == 1:
    #    #print('here')
    #    #print(char_embedding.size())
    #    _, out2 = lstm(char_embedding.unsqueeze(1))
    #    lstm_out.append(out2[0].view(1,-1))    
    #    lstm_out = torch.cat(lstm_out,dim=0)
    #    summarized_lstm,_ = torch.max(lstm_out, 0)
    #    return summarized_lstm
    
    a = word.unsqueeze(0)
    #print(a.size())
    a = a.unsqueeze(0)
    #print(a.size())
    a = conv1(a)
    a = conv2(a)
    a = conv3(a)
    a = conv4(a)
    seg = conv_seg(a)

    seg = linear(seg)
    seg = sig(seg)
    idx = torch.where(seg >= 0.47)
    b = idx[2] + 1
    outputs = []
    outputs.append(torch.tensor(0).unsqueeze(0))

    outputs.append(b)
    outputs.append(torch.tensor(word.size()[0]).unsqueeze(0))
    result = torch.cat(outputs, dim=0)
    morph = []
    morph_char = []
    for cnt, idx in enumerate(result):
        if(cnt == 0):
            continue
        morph.append(word[result[cnt-1]:result[cnt]].unsqueeze(1))
        morph_char.append(chars[result[cnt-1]:result[cnt]])


    
    for m in morph:
        _, out2 = lstm(m)
        lstm_out.append(out2[0].view(1,-1))
    
    #return lstm_out
    lstm_out = torch.cat(lstm_out,dim=0)
    #summarized_lstm,_ = torch.max(lstm_out, 0)
    #summarized_lstm.size()
    return lstm_out,morph_char
In [107]:
dataset = CustomDataset(input_[:2000],output_[:2000],character_vocab, word_vocab)
loader = torch.utils.data.DataLoader(dataset=dataset,batch_size=1000,shuffle=True)
In [108]:
device = 'cuda' if torch.cuda.is_available() else 'cpu'
net = MyModel()
#net = net.to(device)
criterion = torch.nn.MSELoss()
optimizer = optim.Adam(net.parameters(),lr=0.001)
In [143]:
#a =  'hello'
#a[0:3]
for p in net.parameters():
    print(p)
Parameter containing:
tensor([[-0.0843,  0.4593, -0.0694,  ...,  0.1333, -0.8772,  0.1286],
        [-0.0112, -0.0399,  0.7193,  ...,  0.2070,  0.3534, -0.8822],
        [ 0.9462,  0.5140, -1.6100,  ..., -0.9133, -0.3494, -0.1511],
        ...,
        [ 2.2396,  0.5679, -0.2022,  ..., -0.2242, -0.7294,  2.0772],
        [-0.7914,  0.6227, -1.2852,  ..., -0.4904,  0.3192,  1.4718],
        [ 0.2730, -0.0218, -0.1653,  ...,  0.9036,  1.0216, -2.2563]],
       requires_grad=True)
Parameter containing:
tensor([[ 0.2081,  1.9920, -1.3581,  ...,  0.3201,  0.2311, -0.7095],
        [ 0.6023,  0.3342,  1.4850,  ...,  0.7748,  1.1667,  0.2439],
        [ 0.5801,  0.1347, -0.1595,  ..., -0.8043,  1.0215, -1.1601],
        ...,
        [-0.5728, -1.4312, -0.2980,  ..., -0.7440, -1.4177,  1.6842],
        [ 0.4065,  0.2546,  1.2468,  ...,  1.0366,  0.2595,  0.5468],
        [-0.3109,  0.2271, -0.6665,  ...,  0.5310,  1.6688,  1.9888]],
       requires_grad=True)
Parameter containing:
tensor([[[[-0.3268,  0.2377, -0.0823],
          [ 0.2618,  0.1738, -0.1690],
          [ 0.0056,  0.1877, -0.2138]]]], requires_grad=True)
Parameter containing:
tensor([-0.0363], requires_grad=True)
Parameter containing:
tensor([[[[-0.1120, -0.1409,  0.0875],
          [-0.2575,  0.2945, -0.1589],
          [-0.3195,  0.0073,  0.1823]]]], requires_grad=True)
Parameter containing:
tensor([0.2284], requires_grad=True)
Parameter containing:
tensor([[[[ 0.1622, -0.0427, -0.1410],
          [-0.1743, -0.2411,  0.3244],
          [ 0.1395,  0.2226,  0.0103]]]], requires_grad=True)
Parameter containing:
tensor([0.2108], requires_grad=True)
Parameter containing:
tensor([[[[ 0.0840,  0.0430,  0.0287],
          [-0.3325, -0.0155, -0.2976],
          [ 0.1010, -0.0225,  0.0273]]]], requires_grad=True)
Parameter containing:
tensor([-0.1737], requires_grad=True)
Parameter containing:
tensor([[[[0.1646, 0.1988],
          [0.1329, 0.0991]]]], requires_grad=True)
Parameter containing:
tensor([-0.2505], requires_grad=True)
Parameter containing:
tensor([[ 0.0491, -0.0926, -0.1401, -0.1428, -0.0204,  0.1176,  0.0914,  0.1728,
         -0.1824,  0.1111,  0.0420,  0.0375,  0.0098,  0.0233, -0.0367,  0.0809,
         -0.0676, -0.1188,  0.0745, -0.1271,  0.1434,  0.0897,  0.1290, -0.1309,
         -0.1536, -0.1083,  0.1763,  0.1189, -0.1333]], requires_grad=True)
Parameter containing:
tensor([0.1186], requires_grad=True)
Parameter containing:
tensor([[-0.0325, -0.0144,  0.0320,  ...,  0.0940,  0.0527,  0.0079],
        [ 0.0063,  0.0093,  0.0841,  ...,  0.0322,  0.0603, -0.0496],
        [-0.0898,  0.0504,  0.0489,  ..., -0.0821,  0.0955,  0.0003],
        ...,
        [ 0.0547, -0.0293,  0.0064,  ..., -0.0853,  0.0194, -0.0812],
        [-0.0308, -0.0746,  0.0648,  ..., -0.0897,  0.0821, -0.0711],
        [ 0.0359, -0.0037, -0.0926,  ..., -0.0689, -0.0483,  0.0750]],
       requires_grad=True)
Parameter containing:
tensor([[-0.0349, -0.0419, -0.0659,  ...,  0.0156, -0.0883,  0.0222],
        [-0.0610, -0.0800,  0.0952,  ...,  0.0281, -0.0649,  0.0332],
        [ 0.0753,  0.0388, -0.0537,  ...,  0.0878, -0.0053,  0.0141],
        ...,
        [ 0.0890, -0.0134, -0.0002,  ..., -0.0244, -0.0974,  0.0681],
        [ 0.0066,  0.0964, -0.0358,  ...,  0.0012,  0.0581,  0.0341],
        [-0.0574,  0.0511, -0.0965,  ..., -0.0480,  0.0447,  0.0157]],
       requires_grad=True)
Parameter containing:
tensor([ 0.0141, -0.0205,  0.0853,  0.0639, -0.0836, -0.0756,  0.0403,  0.0384,
         0.0607,  0.0574, -0.0387,  0.0645, -0.0103,  0.0388, -0.0424,  0.0108,
         0.0065, -0.0780, -0.0323,  0.0062, -0.0934, -0.0771, -0.0560,  0.0125,
        -0.0806,  0.0540, -0.0676,  0.0316,  0.0553,  0.0520, -0.0620,  0.0958,
        -0.0438,  0.0008,  0.0928,  0.0051, -0.0728,  0.0968,  0.0599,  0.0916,
        -0.0570, -0.0886, -0.0708,  0.0704,  0.0170,  0.0163, -0.0630,  0.0213,
         0.0263, -0.0780, -0.0705,  0.0622, -0.0960, -0.0631,  0.0791,  0.0387,
         0.0643, -0.0956, -0.0313, -0.0500, -0.0734, -0.0282, -0.0868,  0.0741,
         0.0011,  0.0860, -0.0896, -0.0401,  0.0021,  0.0747,  0.0148, -0.0302,
         0.0241,  0.0773,  0.0950, -0.0135, -0.0641,  0.0327, -0.0381,  0.0109,
        -0.0803, -0.0112,  0.0388,  0.0652, -0.0726,  0.0986, -0.0799, -0.0879,
        -0.0843, -0.0616, -0.0067,  0.0142, -0.0993,  0.0906,  0.0359, -0.0076,
         0.0258, -0.0557, -0.0984,  0.0591,  0.0936, -0.0151, -0.0677,  0.0238,
         0.0313,  0.0758, -0.0790, -0.0798,  0.0198, -0.0580, -0.0164, -0.0903,
         0.0329, -0.0223, -0.0339,  0.0192, -0.0210,  0.0147, -0.0948,  0.0559,
        -0.0445,  0.0868, -0.0409, -0.0959,  0.0602,  0.0350,  0.0711,  0.0636,
         0.0120, -0.0122, -0.0572,  0.0143, -0.0191,  0.0900,  0.0286,  0.0733,
        -0.0905, -0.0632,  0.0291,  0.0549,  0.0153, -0.0039,  0.0566, -0.0246,
         0.0253,  0.0465, -0.0605, -0.0060, -0.0943, -0.0709, -0.0806,  0.0496,
        -0.0275, -0.0153,  0.0879,  0.0799, -0.0180,  0.0106, -0.0310, -0.0181,
        -0.0144,  0.0571,  0.0717,  0.0873,  0.0426,  0.0499,  0.0829, -0.0972,
        -0.0758,  0.0328, -0.0130,  0.0286, -0.0393,  0.0615,  0.0755,  0.0394,
         0.0268, -0.0180,  0.0229, -0.0383,  0.0430,  0.0384,  0.0098, -0.0532,
        -0.0416,  0.0435, -0.0989, -0.0581, -0.0648,  0.0367, -0.0037, -0.0085,
         0.0643,  0.0758, -0.0752, -0.0648, -0.0669,  0.0564,  0.0811,  0.0412,
        -0.0864,  0.0771,  0.0251,  0.0085, -0.0014, -0.0069,  0.0781,  0.0244,
         0.0414, -0.0602, -0.0316,  0.0458,  0.0337,  0.0144,  0.0472,  0.0541,
        -0.0403, -0.0234,  0.0379, -0.0279,  0.0808,  0.0905,  0.0972,  0.0386,
         0.0921,  0.0671, -0.0952,  0.0533,  0.0720, -0.0060, -0.0779,  0.0946,
         0.0163, -0.0740,  0.0689,  0.0319,  0.0700,  0.0279,  0.0208,  0.0788,
        -0.0792, -0.0800,  0.0575,  0.0593, -0.0386, -0.0331,  0.0299,  0.0360,
        -0.0591, -0.0525,  0.0715, -0.0288,  0.0865, -0.0275, -0.0288,  0.0037,
        -0.0807, -0.0885, -0.0129, -0.0181,  0.0830, -0.0521,  0.0734,  0.0603,
        -0.0234, -0.0662, -0.0385, -0.0534,  0.0724, -0.0015,  0.0465,  0.0830,
        -0.0344, -0.0957,  0.0343, -0.0062,  0.0367, -0.0844,  0.0706, -0.0984,
         0.0419, -0.0293, -0.0126,  0.0897, -0.0275, -0.0186, -0.0754,  0.0402,
         0.0163,  0.0437, -0.0740,  0.0932,  0.0414, -0.0272, -0.0582,  0.0122,
        -0.0087, -0.0391, -0.0804,  0.0968, -0.0927,  0.0598, -0.0573,  0.0705,
         0.0156, -0.0012,  0.0950,  0.0423, -0.0044,  0.0696, -0.0787,  0.0656,
        -0.0471, -0.0563, -0.0564, -0.0623, -0.0674, -0.0638, -0.0224,  0.0228,
        -0.0309,  0.0535,  0.0506, -0.0322,  0.0770, -0.0503,  0.0125,  0.0922,
         0.0661,  0.0971,  0.0204,  0.0949,  0.0267,  0.0420, -0.0893, -0.0861,
        -0.0975, -0.0121,  0.0280, -0.0488,  0.0280, -0.0486,  0.0210, -0.0524,
         0.0077,  0.0025,  0.0390,  0.0055,  0.0190, -0.0579, -0.0878, -0.0675,
        -0.0941,  0.0072, -0.0726, -0.0386,  0.0020,  0.0225,  0.0424, -0.0777,
         0.0103,  0.0797,  0.0817,  0.0238, -0.0410,  0.0523,  0.0987, -0.0302,
        -0.0557,  0.0823,  0.0600,  0.0519,  0.0881,  0.0331,  0.0394,  0.0967,
        -0.0209,  0.0576,  0.0477, -0.0584,  0.0897,  0.0349, -0.0080,  0.0136,
        -0.0495,  0.0522, -0.0048,  0.0315, -0.0553, -0.0545,  0.0007, -0.0006,
         0.0399,  0.0199,  0.0859, -0.0404, -0.0752,  0.0739, -0.0872, -0.0341],
       requires_grad=True)
Parameter containing:
tensor([-0.0446, -0.0263,  0.0660,  0.0479,  0.0095,  0.0323, -0.0930, -0.0324,
         0.0303, -0.0197, -0.0958, -0.0702,  0.0735,  0.0976,  0.0809,  0.0386,
        -0.0364,  0.0050,  0.0760,  0.0850,  0.0100,  0.0026,  0.0221, -0.0027,
         0.0164,  0.0004, -0.0268, -0.0713,  0.0953, -0.0084, -0.0271, -0.0979,
         0.0472,  0.0853,  0.0202,  0.0502, -0.0220,  0.0486, -0.0522,  0.0105,
        -0.0594, -0.0652, -0.0252, -0.0123,  0.0999,  0.0850, -0.0992,  0.0995,
        -0.0783, -0.0344,  0.0764,  0.0830,  0.0659, -0.0008, -0.0873, -0.0667,
        -0.0371,  0.0827,  0.0796, -0.0366,  0.0810, -0.0789,  0.0398,  0.0910,
        -0.0907, -0.0605,  0.0560,  0.0838, -0.0448, -0.0436,  0.0444, -0.0234,
        -0.0514, -0.0990, -0.0234, -0.0978,  0.0195, -0.0194,  0.0408, -0.0944,
         0.0616,  0.0793, -0.0147,  0.0487,  0.0749,  0.0592, -0.0885, -0.0756,
        -0.0546,  0.0523, -0.0223,  0.0323,  0.0306, -0.0605,  0.0972,  0.0443,
        -0.0622, -0.0061, -0.0360, -0.0419, -0.0253, -0.0118,  0.0570, -0.0449,
         0.0836,  0.0446,  0.0941, -0.0081, -0.0699,  0.0672, -0.0975, -0.0464,
        -0.0864, -0.0768, -0.0583,  0.0525,  0.0091,  0.0055, -0.0368,  0.0898,
         0.0802, -0.0242,  0.0032, -0.0471, -0.0268,  0.0176,  0.0615, -0.0811,
         0.0164,  0.0072, -0.0245,  0.0020, -0.0359, -0.0962,  0.0724,  0.0108,
        -0.0115, -0.0951, -0.0729, -0.0741, -0.0297,  0.0027,  0.0959, -0.0031,
         0.0304,  0.0203,  0.0892, -0.0174, -0.0284, -0.0899,  0.0367, -0.0047,
         0.0128,  0.0278,  0.0670,  0.0737,  0.0019,  0.0268,  0.0380,  0.0807,
         0.0603,  0.0718,  0.0508, -0.0770,  0.0075,  0.0436,  0.0499, -0.0392,
         0.0214, -0.0211,  0.0893,  0.0508,  0.0808, -0.0220, -0.0699, -0.0011,
         0.0243, -0.0185, -0.0850, -0.0223, -0.0907, -0.0793,  0.0615, -0.0875,
         0.0025, -0.0886,  0.0989, -0.0251, -0.0640, -0.0039, -0.0516, -0.0682,
        -0.0098,  0.0819,  0.0058, -0.0946,  0.0313,  0.0928, -0.0630, -0.0439,
         0.0005,  0.0727, -0.0596, -0.0248,  0.0721,  0.0338,  0.0014, -0.0577,
         0.0372, -0.0453,  0.0964,  0.0702,  0.0742, -0.0745,  0.0057,  0.0484,
        -0.0384, -0.0952,  0.0158,  0.0614,  0.0930, -0.0063, -0.0020, -0.0933,
         0.0042,  0.0108, -0.0935, -0.0686, -0.0507, -0.0153,  0.0620, -0.0644,
        -0.0521,  0.0282,  0.0377, -0.0008, -0.0877, -0.0721, -0.0408,  0.0378,
        -0.0160,  0.0090, -0.0255, -0.0787, -0.0190, -0.0613, -0.0514,  0.0614,
        -0.0519, -0.0721,  0.0090,  0.0448, -0.0507,  0.0699, -0.0096,  0.0700,
        -0.0606,  0.0348,  0.0459, -0.0920,  0.0001, -0.0165, -0.0982,  0.0928,
         0.0108, -0.0235,  0.0689,  0.0215, -0.0259, -0.0391,  0.0125,  0.0038,
        -0.0191,  0.0584,  0.0601, -0.0975, -0.0145, -0.0225,  0.0504,  0.0504,
        -0.0105, -0.0682, -0.0839, -0.0023,  0.0390,  0.0995,  0.0995, -0.0471,
         0.0439, -0.0657,  0.0853, -0.0867,  0.0474,  0.0749,  0.0631,  0.0283,
         0.0805,  0.0038,  0.0340,  0.0901, -0.0963,  0.0082, -0.0042, -0.0120,
         0.0919, -0.0311,  0.0612,  0.0116, -0.0612,  0.0742,  0.0899,  0.0951,
        -0.0403, -0.0463,  0.0841,  0.0831, -0.0711, -0.0152,  0.0504,  0.0655,
         0.0430,  0.0369,  0.0844,  0.0842,  0.0752,  0.0517,  0.0676, -0.0458,
         0.0239, -0.0265,  0.0424, -0.0905, -0.0677,  0.0732, -0.0517,  0.0940,
        -0.0828,  0.0327, -0.0704,  0.0468,  0.0619,  0.0911, -0.0931,  0.0007,
        -0.0028,  0.0956, -0.0222, -0.0096, -0.0463,  0.0391,  0.0909, -0.0419,
         0.0465,  0.0970, -0.0972, -0.0392, -0.0812,  0.0916,  0.0486,  0.0359,
         0.0367,  0.0695,  0.0652, -0.0113,  0.0832,  0.0790,  0.0962, -0.0549,
        -0.0023,  0.0922, -0.0386,  0.0025,  0.0400, -0.0495,  0.0562, -0.0012,
        -0.0889, -0.0312,  0.0561, -0.0468, -0.0999,  0.0117,  0.0829,  0.0197,
         0.0940, -0.0783, -0.0832,  0.0114,  0.0903, -0.0047, -0.0156, -0.0399,
         0.0083, -0.0654,  0.0177, -0.0694, -0.0276,  0.0387, -0.0217,  0.0979],
       requires_grad=True)
In [112]:
target_word = input_[10]
word_tensor = convert_into_tensor(target_word)
char_embedding = nn.Embedding(char_len, 30)
#print(word_tensor)
char_embeds =  char_embedding(word_tensor)
x_simple = char_embeds
#print(char_embeds.size())
morph_representation, morphs = get_morph_representation(x_simple,target_word)
#morphs = []

print(morphs)
print(morph_representation.size())
['A', 't', 'l', 'a', 'nt', "a'", 's']
torch.Size([7, 100])
In [140]:
# Train the interpreter by optimizing the loss
retain_graph=True
interpreter_simple.optimize(iteration=5000, lr=0.5, show_progress=True)
  0%|          | 0/5000 [00:00<?, ?it/s]
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-140-765faa33320a> in <module>
      1 # Train the interpreter by optimizing the loss
      2 retain_graph=True
----> 3 interpreter_simple.optimize(iteration=5000, lr=0.5, show_progress=True)

~/workspace/python/pytorch_projects/keio_ai/nlp-recipes/utils_nlp/interpreter/Interpreter.py in optimize(self, iteration, lr, show_progress)
    151             optimizer.zero_grad()
    152             loss = self()
--> 153             loss.backward()
    154             optimizer.step()
    155             if minLoss is None or minLoss > loss:

/usr/local/lib/python3.6/dist-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    164                 products. Defaults to ``False``.
    165         """
--> 166         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    167 
    168     def register_hook(self, hook):

/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.
In [83]:
device = 'cpu'
regularization_simple = calculate_regularization(input_words, net.forward, device=device)
words = ["1", "2", "3", "4", "5"]
# create the interpreter instance
# we recommend you to set hyper-parameter *scale* to 10 * Std[word_embedding_weight]
# 10 * 0.1 in this example
interpreter_simple = Interpreter(
    x=input_words,
    Phi=net.forward,
    regularization=regularization_simple,
    scale=10 * 0.1,
    words=words,
)
interpreter_simple.to(device)
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-83-56584af4571c> in <module>
      1 device = 'cpu'
----> 2 regularization_simple = calculate_regularization(input_words, net.forward, device=device)
      3 words = ["1", "2", "3", "4", "5"]
      4 # create the interpreter instance
      5 # we recommend you to set hyper-parameter *scale* to 10 * Std[word_embedding_weight]

~/workspace/python/pytorch_projects/keio_ai/nlp-recipes/utils_nlp/interpreter/Interpreter.py in calculate_regularization(sampled_x, Phi, reduced_axes, device)
     34         x = sampled_x[n]
     35         if device is not None:
---> 36             x = x.to(device)
     37         s = Phi(x)
     38         if reduced_axes is not None:

AttributeError: 'str' object has no attribute 'to'
In [ ]:
